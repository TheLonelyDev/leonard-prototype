{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track fringerprinter range 0\n",
      "0.0\n",
      "[0]Track fingerprinter ~ @File: 10.mp3.wav @Index: 0 @Arousal: -0.135023075 @Valence: 0.094697975 @ElapsedPrev: 0.4539210796356201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lonely\\pycharmprojects\\untitled\\venv36\\lib\\site-packages\\librosa\\beat.py:309: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  hop_length=hop_length))\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "end",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-936b1f34d8f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'end'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;31m# Json encode the track data (using a NumpyEncoder just in case, this wil cast numpy data to a json formatable value)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: end"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "import numpy\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# Disable warnings, Librosa is throwing some numpy deprecation warnings and we are not interested in those\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data output\n",
    "datafile = 'data4_min_22150hz_fixedmagphase.json'\n",
    "# Data folder\n",
    "basedir = 'C:\\\\Users\\\\Lonely\\\\PycharmProjects\\\\leonard-prototype\\\\MEMD_audio_wav16k'\n",
    "# The sample length\n",
    "length = 2\n",
    "\n",
    "import timeit\n",
    "from presets import Preset\n",
    "import librosa as _librosa\n",
    "librosa = Preset(_librosa)\n",
    "librosa['sr'] = 22150\n",
    "\n",
    "# Internal kitchen past this line :O\n",
    "\n",
    "# Calculate all audio features\n",
    "def load(file, offset, duration):\n",
    "    # Load the file in mono format, for a (duration) timespan and start at timeframe a (to prevent intros misbehaving + generate multiple datasets)\n",
    "    y, sr = librosa.load(file, mono=True, duration=duration, offset=offset, sr=22150, res_type='kaiser_best')#, res_type='kaiser_fast')\n",
    "\n",
    "    out = {\n",
    "        'filename': file,\n",
    "        'arousal': 0,\n",
    "        'valence': 0,\n",
    "    }\n",
    "\n",
    "    # Compute the spectogram\n",
    "    #   Avg execution time: 14ms :(\n",
    "    S = librosa.stft(y)  # 3ms\n",
    "    S_abs = numpy.abs(S)  # <1m\n",
    "    onset_env = librosa.onset.onset_strength(S=S_abs, sr=sr)  # 6ms wuth y, 1ms with S_abs\n",
    "    chroma_stft = librosa.feature.chroma_stft(S=S_abs, sr=sr)  # 6ms\n",
    "\n",
    "    \n",
    "    # The following features are based on https://iopscience.iop.org/article/10.1088/1757-899X/482/1/012019/pdf\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    #   Librosa: https://librosa.github.io/librosa/generated/librosa.feature.zero_crossing_rate.html\n",
    "    #   Avg execution time: 2ms\n",
    "    out['zero_crossing_rate'] = numpy.mean(librosa.feature.zero_crossing_rate(y=y))\n",
    "\n",
    "    # Energy\n",
    "    #   Librosa: https://librosa.github.io/librosa/generated/librosa.feature.rms.html\n",
    "    #   Avg execution time: 2ms\n",
    "    #out['energy'] = numpy.mean(librosa.feature.rms(S=S_abs))\n",
    "    start = time.time()\n",
    "    numpy.mean(librosa.feature.rms(y=y))\n",
    "    #numpy.mean(librosa.feature.rms(S=S_abs))\n",
    "    print(time.time() -start)\n",
    "    #%timeit\n",
    "    # Entropy of Energy\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.feature.spectral_contrast.html\n",
    "    #   Avg exceution time: 4ms (was 6ms)\n",
    "    entropy_of_energy = librosa.feature.spectral_contrast(S=S_abs, sr=sr)\n",
    "    out['entropy_of_energy'] = numpy.mean(entropy_of_energy)\n",
    "    out['entropy_of_energy_std'] = numpy.std(entropy_of_energy)\n",
    "\n",
    "    # Spectral Energy\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.feature.spectral_bandwidth.html\n",
    "    #   Avg execution time: 5ms with magphase/s_abs, 7-8ms with y\n",
    "    spectral_energy = librosa.feature.spectral_bandwidth(S=S_abs, sr=sr)\n",
    "    out['spectral_energy'] = numpy.mean(spectral_energy)\n",
    "    out['spectral_energy_std'] = numpy.std(spectral_energy)\n",
    "\n",
    "    # Spectral Flux\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.onset.onset_strength.html?highlight=onset_strength#librosa.onset.onset_strength\n",
    "    out['spectral_flux'] = numpy.mean(onset_env)\n",
    "\n",
    "    # Spectral Roll-off\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.feature.spectral_rolloff.html\n",
    "    out['spectral_rolloff'] = numpy.mean(librosa.feature.spectral_rolloff(S=S_abs, sr=sr))\n",
    "\n",
    "    # MFCC\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.feature.mfcc.html\n",
    "    counter = 1\n",
    "    for mfcc in (librosa.feature.mfcc(y=y, sr=sr, n_mels=13)):\n",
    "        out[('mfcc%s' % counter)] = numpy.mean(mfcc)\n",
    "        counter = counter + 1\n",
    "\n",
    "    # Chroma Vector (Pitch vector)\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.feature.chroma_stft.html\n",
    "    counter = 1\n",
    "    for chroma in (chroma_stft):\n",
    "        out[('chroma_vector%s' % counter)] = numpy.mean(chroma)\n",
    "        counter = counter + 1\n",
    "\n",
    "    # Chroma Deviation (Pitch deviation)\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.feature.chroma_stft.html\n",
    "    out['chroma_deviation'] = numpy.std(chroma_stft)\n",
    "\n",
    "    # Tempo\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.feature.tempogram.html#librosa.feature.tempogram\n",
    "    #   Librosa: http://librosa.github.io/librosa/generated/librosa.beat.plp.html#librosa.beat.plp\n",
    "    #   Avg execution time: 15ms (this sounds bad, pun intended)\n",
    "    out['tempo'] = numpy.mean(librosa.beat.tempo(onset_envelope=onset_env, sr=sr))\n",
    "\n",
    "    return out\n",
    "\n",
    "# Numpy encoder for json formatting, this is just to make sure that the data cab ve formated (numpy->python values)\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32,\n",
    "            np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj,(np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "# Internal value for sample calc\n",
    "sampleLength = length * 1000\n",
    "\n",
    "# Internal data\n",
    "tracks = []\n",
    "annotations = {'arousal': {}, 'valence': {}}\n",
    "\n",
    "def format(ms):\n",
    "    return ('sample_%sms' % (ms))\n",
    "\n",
    "def computeSample(row, start):\n",
    "    # Interval\n",
    "    interval = 500\n",
    "\n",
    "    data = []\n",
    "    for i in range(0, int(sampleLength/500)):\n",
    "        data.append(row[format(start + (i*interval))])\n",
    "\n",
    "    data = numpy.array(data, dtype=float)\n",
    "\n",
    "    return numpy.mean(data)\n",
    "\n",
    "# File loader\n",
    "def annotation(file, type):\n",
    "    # Open the file\n",
    "    with open(file) as fh:\n",
    "        # Read the csv with a , as delimiter & read as dictionary\n",
    "        rd = csv.DictReader(fh, delimiter=',')\n",
    "\n",
    "        # Loop over all entrues\n",
    "        for row in rd:\n",
    "            # Assign the song id to a local variable & delete it from the row\n",
    "            song_id = row['song_id']\n",
    "            del row['song_id']\n",
    "\n",
    "            # Insert the data row (containing all row (headers) with sample_[x]ms data where x is the amount of ms\n",
    "            annotations[type][\"%s.mp3.wav\" % song_id] = row\n",
    "\n",
    "# Load in the arousal & valence annotations from the dataset\n",
    "annotation('../src/data/arousal.csv', 'arousal')\n",
    "annotation('../src/data/valence.csv', 'valence')\n",
    "\n",
    "# Define how many samples per file we will calculate/fingerprint\n",
    "for i in range(0, 14):\n",
    "    print('Track fringerprinter range %s' % (i))\n",
    "\n",
    "    # Loop over all tracks\n",
    "    for track in os.listdir(basedir):\n",
    "        # Define the start offset/time in seconds (for Librosa)\n",
    "        seconds = 15 + (i * length)\n",
    "\n",
    "        # Assign the time start (for benchmarking)\n",
    "        start = time.time()\n",
    "\n",
    "        # Load the Librosa data & arousal/valence values based on an avg/mean of the arousal/valence during this time\n",
    "        track_data = load(basedir + '/' + track, seconds, length)\n",
    "        track_data['arousal'] = computeSample(annotations['arousal'][track], seconds * 1000)\n",
    "        track_data['valence'] = computeSample(annotations['valence'][track], seconds * 1000)\n",
    "\n",
    "        # 'Pretty print' some output\n",
    "        print('[%s]Track fingerprinter ~ @File: %s @Index: %s @Arousal: %s @Valence: %s @ElapsedPrev: %s' % (i, track, len(tracks), track_data['arousal'], track_data['valence'], time.time() - start))\n",
    "\n",
    "        # Add the computed track_data to the tracks data\n",
    "        tracks.append(track_data)\n",
    "\n",
    "        if True:\n",
    "            raise Exception('end')\n",
    "\n",
    "# Json encode the track data (using a NumpyEncoder just in case, this wil cast numpy data to a json formatable value)\n",
    "with open(datafile, 'w') as file_out:\n",
    "    json.dump(tracks, file_out, cls=NumpyEncoder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
